{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Tools\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "test = pd.read_csv('data/test.csv',index_col='PassengerId')\n",
    "train = pd.read_csv('data/train.csv',index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_eng(df):\n",
    "    # Filling NA of original columns we'll use\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    \n",
    "    # Creating columns\n",
    "    ## Based on the Name column\n",
    "    df['Mr'] = df['Name'].str.contains('Mr') & ~df['Name'].str.contains('Mrs')\n",
    "    df['Mrs'] = df['Name'].str.contains('Mrs')\n",
    "    df['Miss'] = df['Name'].str.contains('Miss')\n",
    "    \n",
    "    ## Based on the Embarked column\n",
    "    df['Cherbourg'] = df['Embarked'].str.contains('C')\n",
    "    df['Southampton'] = df['Embarked'].str.contains('S')\n",
    "    df['Queenstown'] = df['Embarked'].str.contains('Q')\n",
    "       \n",
    "    ## Based on the Sex column\n",
    "    df['Sex'] = ~df['Sex'].str.contains('female')\n",
    "    \n",
    "    ## Based on SibSp and Parch\n",
    "    df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "    \n",
    "    # Combining columns\n",
    "    df['Pclass*Age'] = (df['Pclass']*df['Age']).apply(lambda x: 1/x if x != 0 else 999999999)\n",
    "    df['Fare*Age'] = (df['Fare']*df['Age']).apply(lambda x: 1/x if x != 0 else 999999999)\n",
    "    df['Pclass*Age*Fare'] = df['Pclass*Age']*df['Fare']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_na(df):    \n",
    "    \n",
    "    df['Pclass*Age'] = df['Pclass*Age'].fillna(df['Pclass*Age'].mean())\n",
    "    df['Fare*Age'] = df['Fare*Age'].fillna(df['Fare*Age'].mean())\n",
    "    df['Pclass*Age*Fare'] = df['Pclass*Age*Fare'].fillna(df['Pclass*Age*Fare'].mean())\n",
    "    df[['Cherbourg', 'Southampton', 'Queenstown']] = df[['Cherbourg', 'Southampton', 'Queenstown']].fillna(value = False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_df(df):\n",
    "    \n",
    "    df = data_eng(df)    \n",
    "    # Dropping columns\n",
    "    df = df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "    \n",
    "    return fill_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying data processing on train and then splitting dataset into **X_train** and **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_df(train)\n",
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying data processing on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepare_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "dt = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(), algorithm=\"SAMME.R\", n_estimators=100)\n",
    "xg = xgb.XGBClassifier(n_estimators=100)\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta\n",
    "meta_clf = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "classifiers = [rf, lr, dt, ada, xg, svc, knn]\n",
    "stack_clf = StackingClassifier(classifiers=classifiers, meta_classifier=meta_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = range(1, 3)\n",
    "splits = [10, 18, 30]\n",
    "\n",
    "params = {\n",
    "    'randomforestclassifier__max_depth' : max_depth,\n",
    "    'randomforestclassifier__min_samples_split' : splits,\n",
    "    'decisiontreeclassifier__max_depth' : max_depth,\n",
    "    'decisiontreeclassifier__min_samples_split' : splits,\n",
    "    'xgbclassifier__max_depth' : max_depth\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=StackingClassifier(average_probas=False,\n",
       "          classifiers=[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_...ures=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=False, verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'randomforestclassifier__max_depth': range(1, 3), 'randomforestclassifier__min_samples_split': [10, 18, 30], 'decisiontreeclassifier__max_depth': range(1, 3), 'decisiontreeclassifier__min_samples_split': [10, 18, 30], 'xgbclassifier__max_depth': range(1, 3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Grid Search\n",
    "grid = GridSearchCV(estimator=stack_clf, param_grid=params, cv=5, refit=True, verbose=1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092031425364759"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting results from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'PassengerId':test.index, 'Survived':res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('stacking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
